{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9156\\3630013386.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, requests, json, csv\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Ontology Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load ontology into memory\n",
    "def load_ontology_from_db() -> dict:\n",
    "    conn = psycopg2.connect(os.getenv(\"DATABASE_URL\"))\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    ontology_data = {\n",
    "        \"uberon-tissue\": {},\n",
    "        \"cl-cell\": {},\n",
    "        \"ensembl-gene\": {}\n",
    "    }\n",
    "\n",
    "    table_mappings = [\n",
    "        (\"TISSUE\", \"UBERON\", \"tissueName\", \"uberon-tissue\"),\n",
    "        (\"CELL\", \"CL\", \"cellName\", \"cl-cell\"),\n",
    "        (\"GENE\", \"ENSEMBL\", \"geneName\", \"ensembl-gene\")\n",
    "    ]\n",
    "\n",
    "    for table, key_col, value_col, json_key in table_mappings:\n",
    "        cur.execute(f\"SELECT {key_col}, {value_col} FROM {table}\")\n",
    "        rows = cur.fetchall()\n",
    "        ontology_data[json_key] = {key: value for key, value in rows}\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    return ontology_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "from contextlib import closing\n",
    "\n",
    "def load_ontology_from_db() -> dict:\n",
    "    ontology_data = {\n",
    "        \"uberon-tissue\": {},\n",
    "        \"cl-cell\": {},\n",
    "        \"ensembl-gene\": {}\n",
    "    }\n",
    "\n",
    "    table_mappings = [\n",
    "        (\"TISSUE\", \"UBERON\", \"tissueName\", \"uberon-tissue\"),\n",
    "        (\"CELL\", \"CL\", \"cellName\", \"cl-cell\"),\n",
    "        (\"GENE\", \"ENSEMBL\", \"geneName\", \"ensembl-gene\")\n",
    "    ]\n",
    "\n",
    "    query = \" UNION ALL \".join(\n",
    "        f\"SELECT '{json_key}' AS type, {key_col} AS key, {value_col} AS value FROM {table}\"\n",
    "        for table, key_col, value_col, json_key in table_mappings\n",
    "    )\n",
    "\n",
    "    with closing(psycopg2.connect(os.getenv(\"DATABASE_URL\"))) as conn, conn.cursor() as cur:\n",
    "        cur.execute(query)\n",
    "        for row in cur.fetchall():\n",
    "            json_key, key, value = row\n",
    "            ontology_data[json_key][key] = value\n",
    "\n",
    "    return ontology_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OntologyTranslator:\n",
    "    _ontology_dict = None  # Class-level cache\n",
    "\n",
    "    @classmethod\n",
    "    def _load_ontology(cls):\n",
    "        if cls._ontology_dict is None:\n",
    "            cls._ontology_dict = load_ontology_from_db()\n",
    "\n",
    "    @classmethod\n",
    "    def tissue(cls, value: str, rev: bool = False) -> str | None:\n",
    "        cls._load_ontology()\n",
    "        table = cls._ontology_dict.get(\"uberon-tissue\", {})\n",
    "        return (\n",
    "            next((k for k, v in table.items() if v.lower() == value.lower()), None)\n",
    "            if rev else table.get(value)\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def cell(cls, value: str, rev: bool = False) -> str | None:\n",
    "        cls._load_ontology()\n",
    "        table = cls._ontology_dict.get(\"cl-cell\", {})\n",
    "        return (\n",
    "            next((k for k, v in table.items() if v.lower() == value.lower()), None)\n",
    "            if rev else table.get(value)\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def gene(cls, value: str, rev: bool = False) -> str | None:\n",
    "        cls._load_ontology()\n",
    "        table = cls._ontology_dict.get(\"ensembl-gene\", {})\n",
    "        return (\n",
    "            next((k for k, v in table.items() if v.lower() == value.lower()), None)\n",
    "            if rev else table.get(value)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontl = OntologyTranslator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_read(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        sample = file.read(1024) \n",
    "        file.seek(0)\n",
    "        detected_delimiter = csv.Sniffer().sniff(sample).delimiter    \n",
    "    # Read the file with the detected delimiter\n",
    "    df = pd.read_csv(file_path, sep=detected_delimiter)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"cluster0.csv\"\n",
    "df = csv_read(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Genes by Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clusters(df):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Ensure the column names are correct\n",
    "    if \"cluster\" not in df.columns or \"gene\" not in df.columns:\n",
    "        raise ValueError(\"The file must contain 'Cluster' and 'Gene' columns\")\n",
    "\n",
    "    # Group the data by clusters and pad genes to ensure columns have equal lengths\n",
    "    grouped = df.groupby(\"cluster\")[\"gene\"].apply(list)\n",
    "\n",
    "    # Create a DataFrame where each column is a cluster and rows contain the genes\n",
    "    max_length = max(grouped.apply(len))  # Determine the maximum number of genes in a cluster\n",
    "    return pd.DataFrame({cluster: genes + [None] * (max_length - len(genes)) for cluster, genes in grouped.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KRT14</td>\n",
       "      <td>TXNIP</td>\n",
       "      <td>LY6D</td>\n",
       "      <td>S100A8</td>\n",
       "      <td>TIMP1</td>\n",
       "      <td>ITM2B</td>\n",
       "      <td>TINAGL1</td>\n",
       "      <td>KRT1</td>\n",
       "      <td>KRT16</td>\n",
       "      <td>KRT14</td>\n",
       "      <td>...</td>\n",
       "      <td>IGHG4</td>\n",
       "      <td>FADS2</td>\n",
       "      <td>IGKC</td>\n",
       "      <td>SPRR1B</td>\n",
       "      <td>IGHG4</td>\n",
       "      <td>FASN</td>\n",
       "      <td>LOR</td>\n",
       "      <td>S100A8</td>\n",
       "      <td>COL3A1</td>\n",
       "      <td>COL1A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IFI27</td>\n",
       "      <td>ATP1B3</td>\n",
       "      <td>KRT14</td>\n",
       "      <td>S100A7</td>\n",
       "      <td>APOD</td>\n",
       "      <td>PERP</td>\n",
       "      <td>TM4SF1</td>\n",
       "      <td>GPX2</td>\n",
       "      <td>SBSN</td>\n",
       "      <td>LY6D</td>\n",
       "      <td>...</td>\n",
       "      <td>IGKC</td>\n",
       "      <td>THRSP</td>\n",
       "      <td>IGHG4</td>\n",
       "      <td>S100A7</td>\n",
       "      <td>IGKC</td>\n",
       "      <td>APOC1</td>\n",
       "      <td>FLG2</td>\n",
       "      <td>S100A7</td>\n",
       "      <td>COL1A1</td>\n",
       "      <td>COL3A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COL17A1</td>\n",
       "      <td>MAF</td>\n",
       "      <td>KRT16</td>\n",
       "      <td>SPRR1B</td>\n",
       "      <td>SAA1</td>\n",
       "      <td>GPNMB</td>\n",
       "      <td>IGFBP6</td>\n",
       "      <td>LTF</td>\n",
       "      <td>LY6D</td>\n",
       "      <td>S100A2</td>\n",
       "      <td>...</td>\n",
       "      <td>MYL9</td>\n",
       "      <td>FADS1</td>\n",
       "      <td>IGHG3</td>\n",
       "      <td>SPRR2D</td>\n",
       "      <td>MALAT1</td>\n",
       "      <td>MGST1</td>\n",
       "      <td>ARG1</td>\n",
       "      <td>CSTA</td>\n",
       "      <td>COL1A2</td>\n",
       "      <td>SPARC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HSPA1A</td>\n",
       "      <td>EIF4A2</td>\n",
       "      <td>LGALS7</td>\n",
       "      <td>KRTDAP</td>\n",
       "      <td>IGFBP5</td>\n",
       "      <td>TXNIP</td>\n",
       "      <td>MMP28</td>\n",
       "      <td>CCL27</td>\n",
       "      <td>LGALS7</td>\n",
       "      <td>LGALS7</td>\n",
       "      <td>...</td>\n",
       "      <td>IGHG3</td>\n",
       "      <td>PECR</td>\n",
       "      <td>IGHG1</td>\n",
       "      <td>MUCL1</td>\n",
       "      <td>C1QA</td>\n",
       "      <td>SAA1</td>\n",
       "      <td>LCE1B</td>\n",
       "      <td>KRTDAP</td>\n",
       "      <td>SPARC</td>\n",
       "      <td>MT-CYB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGALS3BP</td>\n",
       "      <td>MMP13</td>\n",
       "      <td>IFI27</td>\n",
       "      <td>SBSN</td>\n",
       "      <td>C3</td>\n",
       "      <td>GJB6</td>\n",
       "      <td>BIRC5</td>\n",
       "      <td>FOSB</td>\n",
       "      <td>KRTDAP</td>\n",
       "      <td>IFI27</td>\n",
       "      <td>...</td>\n",
       "      <td>IGHG1</td>\n",
       "      <td>HSD11B1</td>\n",
       "      <td>JCHAIN</td>\n",
       "      <td>S100A7A</td>\n",
       "      <td>HLA-DRA</td>\n",
       "      <td>AWAT2</td>\n",
       "      <td>KPRP</td>\n",
       "      <td>SPRR1B</td>\n",
       "      <td>POSTN</td>\n",
       "      <td>MT-ND2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EFNA1</td>\n",
       "      <td>CAPN2</td>\n",
       "      <td>S100A2</td>\n",
       "      <td>CRABP2</td>\n",
       "      <td>MMP3</td>\n",
       "      <td>ATP1B3</td>\n",
       "      <td>CA2</td>\n",
       "      <td>EPHB6</td>\n",
       "      <td>DMKN</td>\n",
       "      <td>KRT5</td>\n",
       "      <td>...</td>\n",
       "      <td>JCHAIN</td>\n",
       "      <td>HSD3B1</td>\n",
       "      <td>IGHA1</td>\n",
       "      <td>SPRR1A</td>\n",
       "      <td>MT2A</td>\n",
       "      <td>ACSBG1</td>\n",
       "      <td>WFDC12</td>\n",
       "      <td>GJB6</td>\n",
       "      <td>DCN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RBM42</td>\n",
       "      <td>SULF2</td>\n",
       "      <td>HIST1H1C</td>\n",
       "      <td>SLPI</td>\n",
       "      <td>COMP</td>\n",
       "      <td>CLDN1</td>\n",
       "      <td>CENPW</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>GJB2</td>\n",
       "      <td>TAGLN2</td>\n",
       "      <td>...</td>\n",
       "      <td>IGFBP6</td>\n",
       "      <td>FABP7</td>\n",
       "      <td>IGLC2</td>\n",
       "      <td>IL36RN</td>\n",
       "      <td>MYL9</td>\n",
       "      <td>CYP4F8</td>\n",
       "      <td>LCE1A</td>\n",
       "      <td>MUCL1</td>\n",
       "      <td>COL6A3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HIST1H1C</td>\n",
       "      <td>CEBPG</td>\n",
       "      <td>LSR</td>\n",
       "      <td>IVL</td>\n",
       "      <td>CXCL12</td>\n",
       "      <td>TNFSF10</td>\n",
       "      <td>SERPINA3</td>\n",
       "      <td>TNFRSF19</td>\n",
       "      <td>HIST1H1C</td>\n",
       "      <td>FXYD3</td>\n",
       "      <td>...</td>\n",
       "      <td>SULF1</td>\n",
       "      <td>ACSM6</td>\n",
       "      <td>IGLC1</td>\n",
       "      <td>LCE3E</td>\n",
       "      <td>IGHG1</td>\n",
       "      <td>TLCD4</td>\n",
       "      <td>LCE2C</td>\n",
       "      <td>SLPI</td>\n",
       "      <td>COL5A2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SCPEP1</td>\n",
       "      <td>PALLD</td>\n",
       "      <td>FAM83H</td>\n",
       "      <td>PI3</td>\n",
       "      <td>CCL19</td>\n",
       "      <td>DSG3</td>\n",
       "      <td>RRM2</td>\n",
       "      <td>AC103591.3</td>\n",
       "      <td>CRABP2</td>\n",
       "      <td>HSPB1</td>\n",
       "      <td>...</td>\n",
       "      <td>IGHA1</td>\n",
       "      <td>ACOT1</td>\n",
       "      <td>IGHG2</td>\n",
       "      <td>SLC6A14</td>\n",
       "      <td>ATP6V0C</td>\n",
       "      <td>CLMP</td>\n",
       "      <td>LCE2B</td>\n",
       "      <td>S100A7A</td>\n",
       "      <td>PRRX1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GAMT</td>\n",
       "      <td>PLAU</td>\n",
       "      <td>TMEM79</td>\n",
       "      <td>MUCL1</td>\n",
       "      <td>MMP1</td>\n",
       "      <td>MAF</td>\n",
       "      <td>CCNB2</td>\n",
       "      <td>HLA-DQB2</td>\n",
       "      <td>SLPI</td>\n",
       "      <td>COX6B1</td>\n",
       "      <td>...</td>\n",
       "      <td>GGT5</td>\n",
       "      <td>PKLR</td>\n",
       "      <td>MZB1</td>\n",
       "      <td>SPP1</td>\n",
       "      <td>IGHG3</td>\n",
       "      <td>GLDC</td>\n",
       "      <td>LCE1E</td>\n",
       "      <td>SPP1</td>\n",
       "      <td>COL11A1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1         2       3       4        5         6           7   \\\n",
       "0     KRT14   TXNIP      LY6D  S100A8   TIMP1    ITM2B   TINAGL1        KRT1   \n",
       "1     IFI27  ATP1B3     KRT14  S100A7    APOD     PERP    TM4SF1        GPX2   \n",
       "2   COL17A1     MAF     KRT16  SPRR1B    SAA1    GPNMB    IGFBP6         LTF   \n",
       "3    HSPA1A  EIF4A2    LGALS7  KRTDAP  IGFBP5    TXNIP     MMP28       CCL27   \n",
       "4  LGALS3BP   MMP13     IFI27    SBSN      C3     GJB6     BIRC5        FOSB   \n",
       "5     EFNA1   CAPN2    S100A2  CRABP2    MMP3   ATP1B3       CA2       EPHB6   \n",
       "6     RBM42   SULF2  HIST1H1C    SLPI    COMP    CLDN1     CENPW        ATF3   \n",
       "7  HIST1H1C   CEBPG       LSR     IVL  CXCL12  TNFSF10  SERPINA3    TNFRSF19   \n",
       "8    SCPEP1   PALLD    FAM83H     PI3   CCL19     DSG3      RRM2  AC103591.3   \n",
       "9      GAMT    PLAU    TMEM79   MUCL1    MMP1      MAF     CCNB2    HLA-DQB2   \n",
       "\n",
       "         8       9   ...      17       18      19       20       21      22  \\\n",
       "0     KRT16   KRT14  ...   IGHG4    FADS2    IGKC   SPRR1B    IGHG4    FASN   \n",
       "1      SBSN    LY6D  ...    IGKC    THRSP   IGHG4   S100A7     IGKC   APOC1   \n",
       "2      LY6D  S100A2  ...    MYL9    FADS1   IGHG3   SPRR2D   MALAT1   MGST1   \n",
       "3    LGALS7  LGALS7  ...   IGHG3     PECR   IGHG1    MUCL1     C1QA    SAA1   \n",
       "4    KRTDAP   IFI27  ...   IGHG1  HSD11B1  JCHAIN  S100A7A  HLA-DRA   AWAT2   \n",
       "5      DMKN    KRT5  ...  JCHAIN   HSD3B1   IGHA1   SPRR1A     MT2A  ACSBG1   \n",
       "6      GJB2  TAGLN2  ...  IGFBP6    FABP7   IGLC2   IL36RN     MYL9  CYP4F8   \n",
       "7  HIST1H1C   FXYD3  ...   SULF1    ACSM6   IGLC1    LCE3E    IGHG1   TLCD4   \n",
       "8    CRABP2   HSPB1  ...   IGHA1    ACOT1   IGHG2  SLC6A14  ATP6V0C    CLMP   \n",
       "9      SLPI  COX6B1  ...    GGT5     PKLR    MZB1     SPP1    IGHG3    GLDC   \n",
       "\n",
       "       23       24       25      26  \n",
       "0     LOR   S100A8   COL3A1  COL1A1  \n",
       "1    FLG2   S100A7   COL1A1  COL3A1  \n",
       "2    ARG1     CSTA   COL1A2   SPARC  \n",
       "3   LCE1B   KRTDAP    SPARC  MT-CYB  \n",
       "4    KPRP   SPRR1B    POSTN  MT-ND2  \n",
       "5  WFDC12     GJB6      DCN    None  \n",
       "6   LCE1A    MUCL1   COL6A3    None  \n",
       "7   LCE2C     SLPI   COL5A2    None  \n",
       "8   LCE2B  S100A7A    PRRX1    None  \n",
       "9   LCE1E     SPP1  COL11A1    None  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_df = extract_clusters(df)\n",
    "\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Genes into Ensembl ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_genes(clustered_df):\n",
    "    # Translate gene names to Ensembl IDs in the clustered DataFrame\n",
    "    return clustered_df.apply(lambda col: col.map(lambda gene: ontl.gene(gene, rev=True) if pd.notna(gene) else None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000186847</td>\n",
       "      <td>ENSG00000265972</td>\n",
       "      <td>ENSG00000167656</td>\n",
       "      <td>ENSG00000143546</td>\n",
       "      <td>ENSG00000102265</td>\n",
       "      <td>ENSG00000136156</td>\n",
       "      <td>ENSG00000142910</td>\n",
       "      <td>ENSG00000167768</td>\n",
       "      <td>ENSG00000186832</td>\n",
       "      <td>ENSG00000186847</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000211892</td>\n",
       "      <td>ENSG00000134824</td>\n",
       "      <td>ENSG00000211592</td>\n",
       "      <td>ENSG00000169469</td>\n",
       "      <td>ENSG00000211892</td>\n",
       "      <td>ENSG00000169710</td>\n",
       "      <td>None</td>\n",
       "      <td>ENSG00000143546</td>\n",
       "      <td>ENSG00000168542</td>\n",
       "      <td>ENSG00000108821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000165949</td>\n",
       "      <td>ENSG00000069849</td>\n",
       "      <td>ENSG00000186847</td>\n",
       "      <td>ENSG00000143556</td>\n",
       "      <td>ENSG00000189058</td>\n",
       "      <td>ENSG00000112378</td>\n",
       "      <td>ENSG00000169908</td>\n",
       "      <td>ENSG00000176153</td>\n",
       "      <td>ENSG00000189001</td>\n",
       "      <td>ENSG00000167656</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000211592</td>\n",
       "      <td>ENSG00000151365</td>\n",
       "      <td>ENSG00000211892</td>\n",
       "      <td>ENSG00000143556</td>\n",
       "      <td>ENSG00000211592</td>\n",
       "      <td>ENSG00000130208</td>\n",
       "      <td>ENSG00000143520</td>\n",
       "      <td>ENSG00000143556</td>\n",
       "      <td>ENSG00000108821</td>\n",
       "      <td>ENSG00000168542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000065618</td>\n",
       "      <td>ENSG00000178573</td>\n",
       "      <td>ENSG00000186832</td>\n",
       "      <td>ENSG00000169469</td>\n",
       "      <td>ENSG00000173432</td>\n",
       "      <td>ENSG00000136235</td>\n",
       "      <td>ENSG00000167779</td>\n",
       "      <td>ENSG00000012223</td>\n",
       "      <td>ENSG00000167656</td>\n",
       "      <td>ENSG00000196754</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000101335</td>\n",
       "      <td>ENSG00000149485</td>\n",
       "      <td>ENSG00000211897</td>\n",
       "      <td>ENSG00000163216</td>\n",
       "      <td>ENSG00000251562</td>\n",
       "      <td>ENSG00000008394</td>\n",
       "      <td>ENSG00000118520</td>\n",
       "      <td>ENSG00000121552</td>\n",
       "      <td>ENSG00000164692</td>\n",
       "      <td>ENSG00000113140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000204389</td>\n",
       "      <td>ENSG00000156976</td>\n",
       "      <td>ENSG00000205076</td>\n",
       "      <td>ENSG00000188508</td>\n",
       "      <td>ENSG00000115461</td>\n",
       "      <td>ENSG00000265972</td>\n",
       "      <td>ENSG00000271447</td>\n",
       "      <td>ENSG00000213927</td>\n",
       "      <td>ENSG00000205076</td>\n",
       "      <td>ENSG00000205076</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000211897</td>\n",
       "      <td>ENSG00000115425</td>\n",
       "      <td>ENSG00000211896</td>\n",
       "      <td>ENSG00000172551</td>\n",
       "      <td>ENSG00000173372</td>\n",
       "      <td>ENSG00000173432</td>\n",
       "      <td>ENSG00000196734</td>\n",
       "      <td>ENSG00000188508</td>\n",
       "      <td>ENSG00000113140</td>\n",
       "      <td>ENSG00000198727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000108679</td>\n",
       "      <td>ENSG00000137745</td>\n",
       "      <td>ENSG00000165949</td>\n",
       "      <td>ENSG00000189001</td>\n",
       "      <td>None</td>\n",
       "      <td>ENSG00000121742</td>\n",
       "      <td>ENSG00000089685</td>\n",
       "      <td>ENSG00000125740</td>\n",
       "      <td>ENSG00000188508</td>\n",
       "      <td>ENSG00000165949</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000211896</td>\n",
       "      <td>ENSG00000117594</td>\n",
       "      <td>ENSG00000132465</td>\n",
       "      <td>ENSG00000184330</td>\n",
       "      <td>ENSG00000204287</td>\n",
       "      <td>ENSG00000147160</td>\n",
       "      <td>ENSG00000203786</td>\n",
       "      <td>ENSG00000169469</td>\n",
       "      <td>ENSG00000133110</td>\n",
       "      <td>ENSG00000198763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENSG00000169242</td>\n",
       "      <td>ENSG00000162909</td>\n",
       "      <td>ENSG00000196754</td>\n",
       "      <td>ENSG00000143320</td>\n",
       "      <td>ENSG00000149968</td>\n",
       "      <td>ENSG00000069849</td>\n",
       "      <td>ENSG00000104267</td>\n",
       "      <td>ENSG00000106123</td>\n",
       "      <td>ENSG00000161249</td>\n",
       "      <td>ENSG00000186081</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000132465</td>\n",
       "      <td>ENSG00000203857</td>\n",
       "      <td>ENSG00000211895</td>\n",
       "      <td>ENSG00000169474</td>\n",
       "      <td>ENSG00000125148</td>\n",
       "      <td>ENSG00000103740</td>\n",
       "      <td>ENSG00000168703</td>\n",
       "      <td>ENSG00000121742</td>\n",
       "      <td>ENSG00000011465</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENSG00000126254</td>\n",
       "      <td>ENSG00000196562</td>\n",
       "      <td>None</td>\n",
       "      <td>ENSG00000124107</td>\n",
       "      <td>ENSG00000105664</td>\n",
       "      <td>ENSG00000163347</td>\n",
       "      <td>ENSG00000203760</td>\n",
       "      <td>ENSG00000162772</td>\n",
       "      <td>ENSG00000165474</td>\n",
       "      <td>ENSG00000158710</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000167779</td>\n",
       "      <td>ENSG00000164434</td>\n",
       "      <td>ENSG00000211677</td>\n",
       "      <td>ENSG00000136695</td>\n",
       "      <td>ENSG00000101335</td>\n",
       "      <td>ENSG00000186526</td>\n",
       "      <td>ENSG00000186844</td>\n",
       "      <td>ENSG00000172551</td>\n",
       "      <td>ENSG00000163359</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>ENSG00000153879</td>\n",
       "      <td>ENSG00000105699</td>\n",
       "      <td>ENSG00000163207</td>\n",
       "      <td>ENSG00000107562</td>\n",
       "      <td>ENSG00000121858</td>\n",
       "      <td>ENSG00000196136</td>\n",
       "      <td>ENSG00000127863</td>\n",
       "      <td>None</td>\n",
       "      <td>ENSG00000089356</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000137573</td>\n",
       "      <td>ENSG00000173124</td>\n",
       "      <td>ENSG00000211675</td>\n",
       "      <td>ENSG00000185966</td>\n",
       "      <td>ENSG00000211896</td>\n",
       "      <td>ENSG00000152078</td>\n",
       "      <td>ENSG00000187180</td>\n",
       "      <td>ENSG00000124107</td>\n",
       "      <td>ENSG00000204262</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENSG00000121064</td>\n",
       "      <td>ENSG00000129116</td>\n",
       "      <td>ENSG00000180921</td>\n",
       "      <td>ENSG00000124102</td>\n",
       "      <td>ENSG00000172724</td>\n",
       "      <td>ENSG00000134757</td>\n",
       "      <td>ENSG00000171848</td>\n",
       "      <td>None</td>\n",
       "      <td>ENSG00000143320</td>\n",
       "      <td>ENSG00000106211</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000211895</td>\n",
       "      <td>ENSG00000184227</td>\n",
       "      <td>ENSG00000211893</td>\n",
       "      <td>ENSG00000268104</td>\n",
       "      <td>ENSG00000185883</td>\n",
       "      <td>ENSG00000166250</td>\n",
       "      <td>ENSG00000159455</td>\n",
       "      <td>ENSG00000184330</td>\n",
       "      <td>ENSG00000116132</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENSG00000130005</td>\n",
       "      <td>ENSG00000122861</td>\n",
       "      <td>ENSG00000163472</td>\n",
       "      <td>ENSG00000172551</td>\n",
       "      <td>ENSG00000196611</td>\n",
       "      <td>ENSG00000178573</td>\n",
       "      <td>ENSG00000157456</td>\n",
       "      <td>ENSG00000232629</td>\n",
       "      <td>ENSG00000124107</td>\n",
       "      <td>ENSG00000126267</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000099998</td>\n",
       "      <td>ENSG00000143627</td>\n",
       "      <td>ENSG00000170476</td>\n",
       "      <td>ENSG00000118785</td>\n",
       "      <td>ENSG00000211897</td>\n",
       "      <td>ENSG00000178445</td>\n",
       "      <td>ENSG00000186226</td>\n",
       "      <td>ENSG00000118785</td>\n",
       "      <td>ENSG00000060718</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                1                2                3   \\\n",
       "0  ENSG00000186847  ENSG00000265972  ENSG00000167656  ENSG00000143546   \n",
       "1  ENSG00000165949  ENSG00000069849  ENSG00000186847  ENSG00000143556   \n",
       "2  ENSG00000065618  ENSG00000178573  ENSG00000186832  ENSG00000169469   \n",
       "3  ENSG00000204389  ENSG00000156976  ENSG00000205076  ENSG00000188508   \n",
       "4  ENSG00000108679  ENSG00000137745  ENSG00000165949  ENSG00000189001   \n",
       "5  ENSG00000169242  ENSG00000162909  ENSG00000196754  ENSG00000143320   \n",
       "6  ENSG00000126254  ENSG00000196562             None  ENSG00000124107   \n",
       "7             None  ENSG00000153879  ENSG00000105699  ENSG00000163207   \n",
       "8  ENSG00000121064  ENSG00000129116  ENSG00000180921  ENSG00000124102   \n",
       "9  ENSG00000130005  ENSG00000122861  ENSG00000163472  ENSG00000172551   \n",
       "\n",
       "                4                5                6                7   \\\n",
       "0  ENSG00000102265  ENSG00000136156  ENSG00000142910  ENSG00000167768   \n",
       "1  ENSG00000189058  ENSG00000112378  ENSG00000169908  ENSG00000176153   \n",
       "2  ENSG00000173432  ENSG00000136235  ENSG00000167779  ENSG00000012223   \n",
       "3  ENSG00000115461  ENSG00000265972  ENSG00000271447  ENSG00000213927   \n",
       "4             None  ENSG00000121742  ENSG00000089685  ENSG00000125740   \n",
       "5  ENSG00000149968  ENSG00000069849  ENSG00000104267  ENSG00000106123   \n",
       "6  ENSG00000105664  ENSG00000163347  ENSG00000203760  ENSG00000162772   \n",
       "7  ENSG00000107562  ENSG00000121858  ENSG00000196136  ENSG00000127863   \n",
       "8  ENSG00000172724  ENSG00000134757  ENSG00000171848             None   \n",
       "9  ENSG00000196611  ENSG00000178573  ENSG00000157456  ENSG00000232629   \n",
       "\n",
       "                8                9   ...               17               18  \\\n",
       "0  ENSG00000186832  ENSG00000186847  ...  ENSG00000211892  ENSG00000134824   \n",
       "1  ENSG00000189001  ENSG00000167656  ...  ENSG00000211592  ENSG00000151365   \n",
       "2  ENSG00000167656  ENSG00000196754  ...  ENSG00000101335  ENSG00000149485   \n",
       "3  ENSG00000205076  ENSG00000205076  ...  ENSG00000211897  ENSG00000115425   \n",
       "4  ENSG00000188508  ENSG00000165949  ...  ENSG00000211896  ENSG00000117594   \n",
       "5  ENSG00000161249  ENSG00000186081  ...  ENSG00000132465  ENSG00000203857   \n",
       "6  ENSG00000165474  ENSG00000158710  ...  ENSG00000167779  ENSG00000164434   \n",
       "7             None  ENSG00000089356  ...  ENSG00000137573  ENSG00000173124   \n",
       "8  ENSG00000143320  ENSG00000106211  ...  ENSG00000211895  ENSG00000184227   \n",
       "9  ENSG00000124107  ENSG00000126267  ...  ENSG00000099998  ENSG00000143627   \n",
       "\n",
       "                19               20               21               22  \\\n",
       "0  ENSG00000211592  ENSG00000169469  ENSG00000211892  ENSG00000169710   \n",
       "1  ENSG00000211892  ENSG00000143556  ENSG00000211592  ENSG00000130208   \n",
       "2  ENSG00000211897  ENSG00000163216  ENSG00000251562  ENSG00000008394   \n",
       "3  ENSG00000211896  ENSG00000172551  ENSG00000173372  ENSG00000173432   \n",
       "4  ENSG00000132465  ENSG00000184330  ENSG00000204287  ENSG00000147160   \n",
       "5  ENSG00000211895  ENSG00000169474  ENSG00000125148  ENSG00000103740   \n",
       "6  ENSG00000211677  ENSG00000136695  ENSG00000101335  ENSG00000186526   \n",
       "7  ENSG00000211675  ENSG00000185966  ENSG00000211896  ENSG00000152078   \n",
       "8  ENSG00000211893  ENSG00000268104  ENSG00000185883  ENSG00000166250   \n",
       "9  ENSG00000170476  ENSG00000118785  ENSG00000211897  ENSG00000178445   \n",
       "\n",
       "                23               24               25               26  \n",
       "0             None  ENSG00000143546  ENSG00000168542  ENSG00000108821  \n",
       "1  ENSG00000143520  ENSG00000143556  ENSG00000108821  ENSG00000168542  \n",
       "2  ENSG00000118520  ENSG00000121552  ENSG00000164692  ENSG00000113140  \n",
       "3  ENSG00000196734  ENSG00000188508  ENSG00000113140  ENSG00000198727  \n",
       "4  ENSG00000203786  ENSG00000169469  ENSG00000133110  ENSG00000198763  \n",
       "5  ENSG00000168703  ENSG00000121742  ENSG00000011465             None  \n",
       "6  ENSG00000186844  ENSG00000172551  ENSG00000163359             None  \n",
       "7  ENSG00000187180  ENSG00000124107  ENSG00000204262             None  \n",
       "8  ENSG00000159455  ENSG00000184330  ENSG00000116132             None  \n",
       "9  ENSG00000186226  ENSG00000118785  ENSG00000060718             None  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembl_df = translate_genes(clustered_df)\n",
    "ensembl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis with CellxGene's Gene Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to fetch gene expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_expression_data(cluster, ensembl_ids):\n",
    "    \"\"\"\n",
    "    Fetches gene expression data from the Cellxgene API for a given cluster and list of Ensembl IDs.\n",
    "    \n",
    "    :param cluster: The cluster name.\n",
    "    :param ensembl_ids: List of Ensembl IDs for the cluster.\n",
    "    :return: JSON response from the API or None if an error occurred.\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"filter\": {\n",
    "            \"dataset_ids\": [],\n",
    "            \"development_stage_ontology_term_ids\": [],\n",
    "            \"disease_ontology_term_ids\": [],\n",
    "            \"gene_ontology_term_ids\": ensembl_ids,\n",
    "            \"organism_ontology_term_id\": \"NCBITaxon:9606\",\n",
    "            \"self_reported_ethnicity_ontology_term_ids\": [],\n",
    "            \"sex_ontology_term_ids\": [],\n",
    "            \"publication_citations\": [],\n",
    "        },\n",
    "        \"is_rollup\": True\n",
    "    }\n",
    "\n",
    "    # URL for the POST request\n",
    "    API_URL = \"https://api.cellxgene.cziscience.com/wmg/v2/query\"\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        return response.json()['expression_summary']\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching data for Cluster {cluster}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert the data to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expression_data_to_df(data):\n",
    "    flattened_data = []\n",
    "    for gene_id, anatomical_structures in data.items():\n",
    "        for anatomical_id, cell_types in anatomical_structures.items():\n",
    "            for cell_type_id, aggregated_data in cell_types.items():\n",
    "                metrics = aggregated_data['aggregated']\n",
    "                flattened_data.append({\n",
    "                    'gene': gene_id,\n",
    "                    'tissue': anatomical_id,\n",
    "                    'cell': cell_type_id,\n",
    "                    'expression': metrics.get('me', None),\n",
    "                    'cell count': metrics.get('n', None),\n",
    "                    'cell percentage': metrics.get('pc', None),\n",
    "                    'tissue composition': metrics.get('tpc', None)\n",
    "                })\n",
    "    return pd.DataFrame(flattened_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_expression_data(response_df, TARGET_UBERON_ID):\n",
    "    tissue_df = response_df[response_df['tissue'] == TARGET_UBERON_ID].drop(columns=['tissue'])\n",
    "    return tissue_df[~tissue_df['cell'].isin(['tissue_stats', 'CL:0000000'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to translate the ontology terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_ontology(df):\n",
    "    df['cell'] = df['cell'].apply(lambda x: ontl.cell(x))\n",
    "    df['gene'] = df['gene'].apply(lambda x: ontl.gene(x)).fillna(df['gene'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cell_score(results):\n",
    "    cell_df = results.copy()\n",
    "\n",
    "    # Group by 'cell' and calculate the total cell count for each group\n",
    "    sum_cell_count = cell_df.groupby('cell')['cell count'].sum().reset_index()\n",
    "    sum_cell_count.columns = ['cell', 'total cell count']\n",
    "    cell_df = cell_df.merge(sum_cell_count, on='cell')\n",
    "\n",
    "    cell_df = cell_df[cell_df['total cell count'] >= 100]\n",
    "\n",
    "    # Calculate scores\n",
    "    cell_df['score'] = (1) * ((cell_df['expression'] - cell_df['expression'].min()) / (cell_df['expression'].max() - cell_df['expression'].min())) + (1.5) * (cell_df['cell percentage']) + (2.5) * ((cell_df['cell count'] - cell_df['cell count'].min()) / (cell_df['cell count'].max() - cell_df['cell count'].min()))\n",
    "\n",
    "    # Group by 'cell' and calculate the standard deviation of 'score' for each group\n",
    "    std_scores = cell_df.groupby('cell')['score'].std().reset_index()\n",
    "    std_scores.columns = ['cell', 'std']\n",
    "    cell_df = cell_df.merge(std_scores, on='cell')\n",
    "\n",
    "    # Group by 'cell' and calculate the mean of 'score' for each group\n",
    "    mean_scores = cell_df.groupby('cell')['score'].mean().reset_index().fillna(0)\n",
    "    mean_scores.columns = ['cell', 'mean']\n",
    "    cell_df = cell_df.merge(mean_scores, on='cell')\n",
    "\n",
    "    # Calculate the coefficient of variation (CV) for each cell\n",
    "    cell_df['CV'] = cell_df['std'] / cell_df['mean']\n",
    "\n",
    "    # Group by 'cell' and calculate the kurtosis of 'score' for each group\n",
    "    kurtosis_scores = cell_df.groupby('cell')['score'].apply(pd.Series.kurt).reset_index()\n",
    "    kurtosis_scores.columns = ['cell', 'kurtosis']\n",
    "    cell_df = cell_df.merge(kurtosis_scores, on='cell')\n",
    "\n",
    "    # Normalize the scores\n",
    "    cell_df['std norm'] = (cell_df['std'] - cell_df['std'].min()) / (cell_df['std'].max() - cell_df['std'].min())\n",
    "    cell_df['mean norm'] = (cell_df['mean'] - cell_df['mean'].min()) / (cell_df['mean'].max() - cell_df['mean'].min())\n",
    "    cell_df['CV norm'] = (cell_df['CV'] - cell_df['CV'].min()) / (cell_df['CV'].max() - cell_df['CV'].min())\n",
    "    cell_df['kurtosis norm'] = ((cell_df['kurtosis'] - cell_df['kurtosis'].min()) / (cell_df['kurtosis'].max() - cell_df['kurtosis'].min()))\n",
    "\n",
    "    # Count the number of entries for each cell\n",
    "    cell_counts = cell_df['cell'].value_counts().reset_index()\n",
    "    cell_counts.columns = ['cell', 'count']\n",
    "    cell_df = cell_df.merge(cell_counts, on='cell')\n",
    "\n",
    "    cell_df['cell score'] = (0.1 * (1 - cell_df['std norm']).fillna(0) + 0.7 * cell_df['mean norm'] + 0.1 * (1 - cell_df['CV norm']) + 0.1 * (1 - cell_df['kurtosis norm']).fillna(0)) * cell_df['count']\n",
    "    return cell_df.sort_values(by=['count', 'cell score', 'cell', 'gene'], ascending=[False, False, False, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cell_score(\n",
    "    results,\n",
    "    w_e=1.0, w_p=1.5, w_ct=2.5,             # base score weights\n",
    "    w_m=7.0, w_f=3.0,                       # mean vs flatness weights\n",
    "    alpha=1.0, beta=1.0, gamma=1.0,         # flatness breakdown\n",
    "    w_c=1.0                                 # count weight\n",
    "):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    cell_df = results.copy()\n",
    "\n",
    "    # Calculate total cell count per cell\n",
    "    sum_cell_count = cell_df.groupby('cell')['cell count'].sum().reset_index()\n",
    "    sum_cell_count.columns = ['cell', 'total cell count']\n",
    "    cell_df = cell_df.merge(sum_cell_count, on='cell')\n",
    "\n",
    "    # Adaptive cutoff: max(μ - 0.5σ, min(total count))\n",
    "    mu = cell_df['total cell count'].mean()\n",
    "    sigma = cell_df['total cell count'].std()\n",
    "    minimum = cell_df['total cell count'].min()\n",
    "    min_count = max(mu - 0.5 * sigma, minimum)\n",
    "    cell_df = cell_df[cell_df['total cell count'] >= min_count]\n",
    "\n",
    "    # Normalize expression and cell count\n",
    "    norm_expr = (cell_df['expression'] - cell_df['expression'].min()) / (cell_df['expression'].max() - cell_df['expression'].min())\n",
    "    norm_count = (cell_df['cell count'] - cell_df['cell count'].min()) / (cell_df['cell count'].max() - cell_df['cell count'].min())\n",
    "\n",
    "    # Compute base score\n",
    "    cell_df['score'] = (\n",
    "        w_e * norm_expr +\n",
    "        w_p * cell_df['cell percentage'] +\n",
    "        w_ct * norm_count\n",
    "    )\n",
    "\n",
    "    # Compute flatness components\n",
    "    std_scores = cell_df.groupby('cell')['score'].std().reset_index().rename(columns={'score': 'std'})\n",
    "    mean_scores = cell_df.groupby('cell')['score'].mean().reset_index().rename(columns={'score': 'mean'})\n",
    "    kurtosis_scores = cell_df.groupby('cell')['score'].apply(pd.Series.kurt).reset_index(name='kurtosis')\n",
    "\n",
    "    cell_df = cell_df.merge(std_scores, on='cell')\n",
    "    cell_df = cell_df.merge(mean_scores, on='cell')\n",
    "    cell_df = cell_df.merge(kurtosis_scores, on='cell')\n",
    "\n",
    "    cell_df['CV'] = cell_df['std'] / (cell_df['mean'].replace(0, np.nan))\n",
    "\n",
    "    # Normalize flatness metrics\n",
    "    for col in ['std', 'CV', 'kurtosis', 'mean']:\n",
    "        col_min, col_max = cell_df[col].min(), cell_df[col].max()\n",
    "        cell_df[f'{col} norm'] = (cell_df[col] - col_min) / (col_max - col_min + 1e-9)\n",
    "\n",
    "    # Stability (flatness) score\n",
    "    stability = (\n",
    "        alpha * (1 - cell_df['std norm'].fillna(0)) +\n",
    "        beta * (1 - cell_df['CV norm'].fillna(0)) +\n",
    "        gamma * (1 - cell_df['kurtosis norm'].fillna(0))\n",
    "    )\n",
    "    flatness_weight = stability / (alpha + beta + gamma)\n",
    "\n",
    "    # Count-based log-scaled soft weight\n",
    "    cell_counts = cell_df['cell'].value_counts().reset_index()\n",
    "    cell_counts.columns = ['cell', 'count']\n",
    "    cell_df = cell_df.merge(cell_counts, on='cell')\n",
    "\n",
    "    log_scaled_count = np.log1p(cell_df['count']) / np.log1p(cell_df['count'].max())\n",
    "\n",
    "    # Final cell score\n",
    "    cell_df['cell score'] = (\n",
    "        (w_m * cell_df['mean norm'] + w_f * flatness_weight) *\n",
    "        (1 + w_c * log_scaled_count)\n",
    "    )\n",
    "\n",
    "    return cell_df.sort_values(by=['count', 'cell score', 'cell', 'gene'], ascending=[False, False, False, True]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_processing(cluster, ensembl_ids, target_uberon_id):\n",
    "    try:\n",
    "        data = fetch_expression_data(cluster, ensembl_ids)\n",
    "\n",
    "        response_df = expression_data_to_df(data)\n",
    "\n",
    "        filtered_df = filter_expression_data(response_df, target_uberon_id)\n",
    "\n",
    "        translated_df = translate_ontology(filtered_df)\n",
    "\n",
    "        ranked_df = calculate_cell_score(translated_df)\n",
    "\n",
    "        return ranked_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the pipeline execution: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_data_analysis(ensembl_df, target_uberon_id):\n",
    "    results = {}\n",
    "\n",
    "    # Iterate over each cluster (column) in the DataFrame\n",
    "    for cluster in ensembl_df.columns:\n",
    "        # Extract Ensembl IDs for the current cluster, dropping any NaN values\n",
    "        ensembl_ids = ensembl_df[cluster].dropna().tolist()\n",
    "        \n",
    "        if not ensembl_ids:\n",
    "            continue\n",
    "        \n",
    "        # Run the expression pipeline for the current cluster\n",
    "        result_df = run_data_processing(cluster, ensembl_ids, target_uberon_id)\n",
    "        \n",
    "        # Store the result in the dictionary\n",
    "        results[cluster] = result_df.reset_index(drop=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Display the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def display_dataframe_as_markdown(df):\n",
    "    markdown_table = df.to_markdown(index=False)\n",
    "    display(Markdown(markdown_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the UBERON ID to filter\n",
    "TARGET_UBERON_ID = \"UBERON:0002097\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the main pipeline\n",
    "results = main_data_analysis(ensembl_df, TARGET_UBERON_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframe_as_markdown(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]['cell'].unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_df = results[0].copy()\n",
    "unique_cells = ex_df['cell'].unique()[:10]\n",
    "\n",
    "ex_df = ex_df[ex_df['cell'].isin(unique_cells)][['cell', 'cell score']].drop_duplicates().reset_index(drop=True)\n",
    "ex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0][results[0]['cell']=='epithelial cell'][['gene', 'expression', 'cell count', 'cell percentage', 'tissue composition', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_dataframe(df, n=10):\n",
    "    unique_cells = df['cell'].unique()[:n]\n",
    "    filtered_df = df[df['cell'].isin(unique_cells)]\n",
    "\n",
    "    final_df = (\n",
    "        filtered_df.groupby('cell', as_index=False)\n",
    "        .agg({'gene': lambda x: \", \".join(map(str, set(x))), \n",
    "              'cell score': lambda x: \", \".join(map(str, set(x)))})\n",
    "    ).sort_values(by=['cell score'], ascending=[False])\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = export_dataframe(results[0])\n",
    "display_dataframe_as_markdown(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top3_cells(df):\n",
    "    return df['cell'].unique()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_top3_cells(results):\n",
    "\n",
    "    top3cells = pd.DataFrame()\n",
    "    for cluster in results:\n",
    "        top3cells[f'{cluster}'] = get_top3_cells(results[cluster])\n",
    "\n",
    "    top3cellsT = top3cells.T.reset_index()\n",
    "    top3cellsT.columns = ['Cluster'] + [f'Cell {i+1}' for i in range(top3cellsT.shape[1]-1)]\n",
    "\n",
    "    return top3cellsT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframe_as_markdown(export_top3_cells(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation with Tavily and Gemini Connected to a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from tavily import TavilyClient\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Initialize Tavily and Gemini clients\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL\n",
    "def get_db_connection():\n",
    "    return psycopg2.connect(os.getenv(\"DATABASE_URL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_database(tissue_name, cell_name, gene_name):\n",
    "    query = \"\"\"\n",
    "        SELECT relationcertainty FROM gene_expression\n",
    "        WHERE uberon = (\n",
    "            SELECT uberon \n",
    "            FROM tissue \n",
    "            WHERE tissuename = %s\n",
    "        )\n",
    "        AND cl = (\n",
    "            SELECT cl \n",
    "            FROM cell \n",
    "            WHERE cellname = %s\n",
    "        )\n",
    "        AND ensembl = (\n",
    "            SELECT ensembl \n",
    "            FROM gene \n",
    "            WHERE genename = %s\n",
    "        )\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with get_db_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query, (tissue_name, cell_name, gene_name))\n",
    "                result = cur.fetchone()\n",
    "                return result[0] if result else None\n",
    "    except Exception as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query Tavily using SDK\n",
    "def query_tavily(tissue_name, cell_name, gene_name):\n",
    "    query = f\"Does {cell_name} express {gene_name} in {tissue_name}?\"\n",
    "    try:\n",
    "        response = tavily_client.search(query= query, search_depth= \"basic\")\n",
    "        sources = [result[\"url\"] for result in response.get(\"results\", [])]\n",
    "        return sources if sources else None\n",
    "    except Exception as e:\n",
    "        print(f\"Tavily Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize using OpenAI\n",
    "def summarize_with_openai(tissue_name, cell_name, gene_name, sources):\n",
    "    prompt = f\"\"\"\n",
    "    Given the following sources, determine the confidence level that {cell_name} expresses {gene_name} in {tissue_name}.\n",
    "    Return one of these values in valid JSON format:\n",
    "    {{\"status\": 1.0}} → Yes\n",
    "    {{\"status\": 0.67}} → Mostly Yes\n",
    "    {{\"status\": 0.33}} → Mostly No\n",
    "    {{\"status\": 0.0}} → No\n",
    "    never return with markdown formatting.\n",
    "    Sources: {sources}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are an expert in cellular biology.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "        return json.loads(output)[\"status\"]\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_database(tissue_name, cell_name, gene_name, source_urls, certainty):\n",
    "    conn = psycopg2.connect(os.getenv(\"DATABASE_URL\"))\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Lookup IDs\n",
    "        cur.execute(\"SELECT uberon FROM tissue WHERE tissuename = %s\", (tissue_name,))\n",
    "        uberon = cur.fetchone()\n",
    "        if not uberon:\n",
    "            raise ValueError(f\"Tissue '{tissue_name}' not found.\")\n",
    "        uberon = uberon[0]\n",
    "\n",
    "        cur.execute(\"SELECT cl FROM cell WHERE cellname = %s\", (cell_name,))\n",
    "        cl = cur.fetchone()\n",
    "        if not cl:\n",
    "            raise ValueError(f\"Cell '{cell_name}' not found.\")\n",
    "        cl = cl[0]\n",
    "\n",
    "        cur.execute(\"SELECT ensembl FROM gene WHERE genename = %s\", (gene_name,))\n",
    "        ensembl = cur.fetchone()\n",
    "        if not ensembl:\n",
    "            raise ValueError(f\"Gene '{gene_name}' not found.\")\n",
    "        ensembl = ensembl[0]\n",
    "\n",
    "        # Insert or update gene_expression\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO gene_expression (uberon, cl, ensembl, relationcertainty)\n",
    "            VALUES (%s, %s, %s, %s)\n",
    "            ON CONFLICT (uberon, cl, ensembl)\n",
    "            DO UPDATE SET relationcertainty = EXCLUDED.relationcertainty\n",
    "            RETURNING expressionid\n",
    "        \"\"\", (uberon, cl, ensembl, certainty))\n",
    "        expressionid = cur.fetchone()[0]\n",
    "\n",
    "        # Insert sources and validate links\n",
    "        for url in source_urls:\n",
    "            # Check or insert source\n",
    "            cur.execute(\"SELECT sourceid FROM source WHERE url = %s\", (url,))\n",
    "            row = cur.fetchone()\n",
    "            if row:\n",
    "                sourceid = row[0]\n",
    "            else:\n",
    "                cur.execute(\"INSERT INTO source (url) VALUES (%s) RETURNING sourceid\", (url,))\n",
    "                sourceid = cur.fetchone()[0]\n",
    "\n",
    "            # Insert validate link if not exists\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO validate (expressionid, sourceid)\n",
    "                VALUES (%s, %s)\n",
    "                ON CONFLICT DO NOTHING\n",
    "            \"\"\", (expressionid, sourceid))\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"✅ Inserted/Updated expressionid {expressionid} with sources.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_cell_gene_relation(tissue_name, cell_name, gene_name):\n",
    "    print(f\"\\n[Validation Start] Processing: {tissue_name} - {cell_name} - {gene_name}\")\n",
    "\n",
    "    # Step 2: Check database first\n",
    "    stored_status = check_database(tissue_name, cell_name, gene_name)\n",
    "    if stored_status is not None:\n",
    "        print(f\"[Validation] Relation already exists in DB with status {stored_status}. Skipping process.\")\n",
    "        return float(stored_status)  # Ensure status is returned as a float\n",
    "\n",
    "    # Step 3: Query Tavily\n",
    "    try:\n",
    "        sources = query_tavily(tissue_name, cell_name, gene_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Tavily Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Step 3a: If no sources found, set status to 0.0 and insert into database\n",
    "    if not sources:\n",
    "        status = 0.0\n",
    "        print(f\"[Validation] No references found in Tavily. Setting status to {status}.\")\n",
    "        insert_into_database(tissue_name, cell_name, gene_name, [], status)\n",
    "        return float(status)  # Ensure status is a float\n",
    "\n",
    "    # Step 4: Summarize with OpenAI\n",
    "    status = summarize_with_openai(tissue_name, cell_name, gene_name, sources)\n",
    "    status = float(status)  # Ensure status is a float\n",
    "    print(f\"[Validation] OpenAI summary status: {status}\")\n",
    "\n",
    "    # Step 5: Insert into Database\n",
    "    insert_into_database(tissue_name, cell_name, gene_name, sources, status)\n",
    "    print(f\"[Validation] Inserted/Updated in DB with status: {status}\")\n",
    "\n",
    "    return status  # Return the validation score as a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_cell_gene_relation(\"skin of body\", \"neural cell\", \"MMP3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = results.copy()\n",
    "for cluster in x_df:\n",
    "    unique_cells = x_df[cluster]['cell'].unique()[:10]\n",
    "    x_df[cluster] = x_df[cluster][['gene', 'cell', 'cell score']][x_df[cluster]['cell'].isin(unique_cells)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframe_as_markdown(x_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_data_validation(results, target_uberon_id):\n",
    "    ex_df = results.copy()\n",
    "    for cluster in ex_df:\n",
    "        unique_cells = ex_df[cluster]['cell'].unique()[:10]\n",
    "        ex_df[cluster] = ex_df[cluster][['gene', 'cell', 'cell score']][ex_df[cluster]['cell'].isin(unique_cells)]\n",
    "    tissue_name = ontl.tissue(target_uberon_id)\n",
    "\n",
    "    for cluster in ex_df:\n",
    "        ex_df[cluster][\"certainty score\"] = ex_df[cluster].apply(lambda row: validate_cell_gene_relation(tissue_name, row[\"cell\"], row[\"gene\"]), axis=1)\n",
    "\n",
    "    return ex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = main_data_validation(results, TARGET_UBERON_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = res[0].copy()\n",
    "mean_certainty = valid_df.groupby('cell')['certainty score'].mean().reset_index().rename(columns={'certainty score': 'cell certainty'})\n",
    "final_df = valid_df.merge(mean_certainty, on='cell')\n",
    "\n",
    "\n",
    "unique_cells = final_df['cell'].unique()\n",
    "final_df = final_df[['cell', 'cell score', 'cell certainty']][final_df['cell'].isin(unique_cells)].drop_duplicates().reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_validation_dataframe(results):\n",
    "    ex_df = results.copy()\n",
    "    for cluster in ex_df:\n",
    "        mean_certainty = ex_df[cluster].groupby('cell')['certainty score'].mean().reset_index().rename(columns={'certainty score': 'cell certainty'})\n",
    "        ex_df[cluster] = ex_df[cluster].merge(mean_certainty, on='cell')\n",
    "\n",
    "        unique_cells = ex_df[cluster]['cell'].unique()[:10]\n",
    "        ex_df[cluster] = ex_df[cluster][['cell', 'cell score', 'cell certainty']][ex_df[cluster]['cell'].isin(unique_cells)].drop_duplicates().reset_index(drop=True)\n",
    "    return ex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = export_validation_dataframe(res)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframe_as_markdown(tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframe_as_markdown(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframe_as_markdown(mean_certainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in results:\n",
    "    valids = {}\n",
    "    print(f\"\\nProcessing Cluster: {cluster}\")\n",
    "    valids[cluster] = data_validation(results[cluster], tl.tl_uberon(TARGET_UBERON_ID)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframe_as_markdown(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis using OpenAI and Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "from langchain_core.runnables import RunnableConfig, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.runnables import chain\n",
    "from tavily import TavilyClient\n",
    "import ast\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\", \n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily = TavilyClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(\n",
    "    max_results=10,\n",
    "    search_depth=\"basic\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=False,\n",
    "    include_images=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tool.invoke('is epithelial cell of skin of body tissue related to these genes: [COL17A1, EFNA1, GAMT, HSPA1A, IFI27, KRT14, LGALS3BP, RBM42, SCPEP1]?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(f\"answer with yes or no. based on this search results,\\n{res}\\n, is epithelial cell of skin of body tissue related to these genes: [COL17A1, EFNA1, GAMT, HSPA1A, IFI27, KRT14, LGALS3BP, RBM42, SCPEP1]?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue = tl.tl_uberon(TARGET_UBERON_ID)\n",
    "tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = final_df['cell'][0]\n",
    "cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = [final_df['gene'][0]]\n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"is {cell} of {tissue} tissue related to these genes: {genes}?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are an expert in cellular biology. answer with a boolean array\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = export_dataframe(results[0])\n",
    "display_dataframe_as_markdown(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchAPIWrapper()\n",
    "tavily_tool = TavilySearchResults(api_wrapper=search)\n",
    "\n",
    "# initialize the agent\n",
    "agent = create_conversational_retrieval_agent(\n",
    "    llm,\n",
    "    tools=[tavily_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(cell_name, gene_names: list):\n",
    "    return f\"answer with yes or no. Is {cell_name} related to this genes: {gene_names}?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names = results[0]['cell'].unique()[:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = results[0][results[0]['cell'] == cell_names[1]]['gene'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = generate_queries(cell_names[1], gene_names)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the agent\n",
    "resp = agent.invoke(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "client = MongoClient(os.getenv(\"MONGO_URI\"), server_api=ServerApi('1'))\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON Output formatter  \n",
    "class CellAnnotation(BaseModel):\n",
    "    class cell(BaseModel):\n",
    "        cell_type : str = Field(description=\"name of the chosen cell.\")\n",
    "        reason : str = Field(description=\"explain the reasoning for choosing the cell. give comments about parameters from the data that support the choice.\")\n",
    "        \n",
    "    explanation : list[str] = Field(description=\"explanation of your reasoning step by step. focus on the parameters and number of genes expressed that support the choice of the cell.\")\n",
    "    cells : list[cell]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                                          \n",
    "You are an expert in analyzing single-cell RNA sequencing (scRNA-seq) data. Your goal is to identify the top 5 most similar cell types to a given, unannotated cell cluster, based on a limited dataset.\n",
    "\n",
    "The dataset is structured as follows:\n",
    "\n",
    "Each row represents a known cell type expressing top genes from a cluster. The columns are: \"Gene\" (top gene expressed in the cluster), \"Cell Name\" (the known cell type expressing the gene), \"Expression Value\" (level of expression), \"Cell Percentage\" (percentage of cells expressing the gene), \"Cell Count\" (number of cells), and \"Tissue Composition\" (percentage of cells in the tissue).\n",
    "\n",
    "Given this dataset, outline the steps to create and apply a scoring system, then finally return a table of top 5 possible cell type identities for the cluster, and its calculated value.\n",
    "\n",
    "Ensure that:\n",
    "1. Describe each row of the dataset, and what it represents.\n",
    "2. What metric is being used, and what value do they indicate.\n",
    "3. The steps for scoring each possible cell type.\n",
    "4. How to obtain the top five possible candidates.                                      \n",
    "\"\"\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser(pydantic_object=CellAnnotation)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an expert in single-cell RNA sequencing.\n",
    "\n",
    "        I have a cluster of cells with its genes as follow\n",
    "\n",
    "        {initial_df}\n",
    "\n",
    "        with the gene expression of each cell\n",
    "\n",
    "        {expression_data}\n",
    "\n",
    "        Based on the given data, which cell is the most valid to be annotated for this cluster of cells according to you?\n",
    "        \n",
    "        \\n{format_instructions}\"\"\",\n",
    "    input_variables=[\"initial_df\", \"expression_data\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'initial_df': initial_df, 'expression_data': results[0].to_csv(sep='\\t', index=False)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"o3-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You are an expert in analyzing single-cell RNA sequencing (scRNA-seq) data. Your goal is to identify the top 5 most similar cell types to a given, unannotated cell cluster, based on a limited dataset. You will do this by creating and applying a scoring system.\n",
    "\n",
    "The dataset is structured as follows:\n",
    "\n",
    "Each row represents the cells that strongly express a top genes from the cluster. The columns are: \"Gene\" (a top gene expressed in the cluster), \"Cell Name\" (the known cell type expressing the gene), \"Expression Value\" (level of expression), \"Cell Percentage\" (percentage of cells expressing the gene), \"Cell Count\" (number of cells), and \"Tissue Composition\" (percentage of cells in the tissue).\n",
    "\n",
    "Follow these steps precisely to prepare the information, which will be automatically formatted into JSON:\n",
    "\n",
    "**Step 1: Data Understanding**\n",
    "\n",
    "*   Explain what each row in the dataset represents. Specifically, explain that each row shows a potential connection between the top gene from the cluster and one known cell type, and the metrics for THAT cell type, not for the cluster itself.\n",
    "*   Explain the meaning of each column: \"Gene\", \"Cell Name\", \"Expression Value\", \"Cell Percentage\", \"Cell Count\", and \"Tissue Composition.\" For each, explain what a higher or lower value might indicate *in the context of identifying similarity to the unannotated cluster*.\n",
    "\n",
    "**Step 2: Develop a Scoring Function (CellTypeScore)**\n",
    "\n",
    "*   Explain that the goal is to assign each known \"Cell Name\" (cell type) a score that reflects its similarity to the unannotated cluster.\n",
    "*   Propose a formula for calculating a `GeneScore` for each *Gene* within each *Cell Name*. This formula should incorporate both \"Cell Percentage\" and \"Expression Value\". Justify why you chose to include these two metrics and how they are combined.\n",
    "*   Propose a formula for combining the `GeneScore` values across all the `Gene` entries for a given \"Cell Name\" to calculate a final overall `CellTypeScore` for that cell type.\n",
    "\n",
    "**Step 3: Calculate CellTypeScore for All Cell Names**\n",
    "\n",
    "*   Explain that the goal is to now apply your scoring system to the known \"Cell Name\" values and find out which ones are the highest, with relation to what each Gene expresses.\n",
    "*   Describe in precise steps what it should do: go through each unique \"Cell Name\" in the dataset, calculate a `GeneScore` and `CellTypeScore` based on Gene, Expression Value, and the percentage that are expressed.\n",
    "\n",
    "**Step 4: Identify Top 5 Candidates**\n",
    "\n",
    "*   Explain how to identify the top 5 candidates from the `CellTypeScore` values, now that they have been calculated in Step 3.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions =\"\"\"\n",
    "You are an expert in analyzing single-cell RNA sequencing (scRNA-seq) data. Your goal is to identify the top 3 most similar cell types to a given, unannotated cell cluster, based on a limited dataset.\n",
    "\n",
    "The dataset is structured as follows:\n",
    "\n",
    "Each row represents a known cell type expressing top genes from a cluster. The columns are: \"Gene\" (top gene expressed in the cluster), \"Cell Name\" (the known cell type expressing the gene), \"Expression Value\" (level of expression), \"Cell Percentage\" (percentage of cells expressing the gene), \"Cell Count\" (number of cells), and \"Tissue Composition\" (percentage of cells in the tissue).\n",
    "\n",
    "Given this dataset, analyze the dataset to determine similarity, then finally return a list of top possible cell type identities for the cluster.\n",
    "\n",
    "Ensure that:\n",
    "1. Never make any assumption. If a gene is not expressed, it should be treated as such and not used for consideration.\n",
    "2. Understand each row of the data and what it represents.\n",
    "3. Prioritize cell types that's expressing more genes from the cluster, then consider the cell count, cell percentage, and expression value.\n",
    "4. The steps for determining each possible cell type.\n",
    "5. How to obtain the top three possible candidates.\n",
    "6. give the explanation as if writing a report\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions =\"\"\"\n",
    "You are an expert in analyzing single-cell RNA sequencing (scRNA-seq) data. Your goal is to identify the top 3 most similar cell types to a given, unannotated cell cluster, based on a limited dataset.\n",
    "\n",
    "The dataset is structured as follows:\n",
    "Each row represents a known cell type expressing top genes from a cluster. The columns are: \"Gene\" (top gene expressed in the cluster), \"Cell Name\" (the known cell type expressing the gene), \"Expression Value\" (level of expression), \"Cell Percentage\" (percentage of cells expressing the gene), \"Cell Count\" (number of cells), and \"Tissue Composition\" (percentage of cells in the tissue).\n",
    "Given this dataset, analyze the dataset to determine similarity, then finally return a list of top possible cell type identities for the cluster. The dataset does not contain any representation of the unannotated cell cluster.\n",
    "\n",
    "Cell similiarity is determined by the number of genes expressed in the cell then the cell count, cell percentage, and expression value. The more genes expressed in a cell, the higher the cell count, cell percentage, and expression value, the more similar the cell is to the unannotated cell cluster. the number of genes expressed in the cell is the most important factor in determining the similarity of the cell to the unannotated cell cluster.\n",
    "\n",
    "Follow these steps precisely to prepare the information\n",
    "Step 1 : Read the whole dataset\n",
    "Step 2 : Explain to me what do you think about each cell's similiarity to the unannotated cell cluster based on the given data.\n",
    "Step 3 : Based on you analysis, what are the top 3 possible cell type identities for the cluster?\n",
    "\n",
    "Ensure that:\n",
    "1. Never make any assumption. If a gene is not expressed, it should be treated as such and not used for consideration.\n",
    "2. Do not consider cells that expressing lesser amount of genes from the cluster.\n",
    "3. Do not consider cells that express a gene with parameters that deviate too much from other genes expressed by that cell.\n",
    "4. Explanations must be written like a report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON Output formatter  \n",
    "class CellAnnotation(BaseModel):\n",
    "    class top_cell(BaseModel):\n",
    "        class gene(BaseModel):\n",
    "            gene_name : str = Field(description=\"Name of the gene expressed by the cell type\")\n",
    "            metrics : str = Field(description=\"cell count, cell percentage, and expression value of the gene\")\n",
    "        \n",
    "        cell_type : str = Field(description=\"name of the chosen cell.\")\n",
    "        gene_info : list[gene]\n",
    "        reason : str = Field(description=\"explain the reasoning for choosing the cell. give comments about parameters from the data that support the choice.\")\n",
    "    \n",
    "    explanation : list[str] = Field(description=\"explanation of your reasoning step by step. focus on the parameters and number of genes expressed that support the choice of the cell.\")\n",
    "    cells : list[top_cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0].to_csv(sep='\\t', index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = f\"expression data : {results[23].drop(columns=['tissue composition']).to_csv(sep='\\t', index=False)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model = 'gpt-4o-mini-2024-07-18',\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \n",
    "         \"content\": instructions},\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": content}\n",
    "    ],\n",
    "    temperature=0.0,\n",
    "    response_format=CellAnnotation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reasoning Model\n",
    "response = client.chat.completions.create(\n",
    "    model = \"o3-mini\",\n",
    "    reasoning_effort=\"medium\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \n",
    "         \"content\": \"\"\"\n",
    "            - You are an expert in single-cell RNA sequencing. \n",
    "            - You will be provided with cell clustering data and gene expression data for each cell. \n",
    "            - Based on the given data, you need to identify the 4 most valid cell to be annotated for the cluster. \n",
    "            - Provide a list of cells in the order of validity and explain your reasoning step by step. only give out the name of the cells from the given data.\n",
    "            - Analyze only the data provided. Do not reference or infer from any external sources\n",
    "            - the answer is in the format of \n",
    "                {\n",
    "                cells : [cell1, cell2, cell3, cell4],\n",
    "                explanation : <explanation>\n",
    "                }\n",
    "            \"\"\"},\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": content}\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.parsed.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output_dict = json.loads(completion.choices[0].message.parsed.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict['cells']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'Values': [5, 3, 8, 2, 9, 1, 7, 4, 6, 5, 3, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define normalization (scale from min=1 to max=9)\n",
    "norm = mcolors.Normalize(vmin=1, vmax=9)\n",
    "# Choose a colormap (reversed for light→dark)\n",
    "cmap = plt.get_cmap('YlGnBu_r')  # Or 'Blues_r', 'Greys_r', etc.\n",
    "\n",
    "# Map values to hex color codes\n",
    "df['Color'] = df['Values'].apply(\n",
    "    lambda x: mcolors.to_hex(cmap(norm(x)))  # Convert to hex\n",
    ")\n",
    "\n",
    "# Display DataFrame with hex color codes\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "def get_marker(tissue, cell):\n",
    "   # URL to send the POST request to\n",
    "    url = \"https://api.cellxgene.cziscience.com/wmg/v2/markers\"\n",
    "\n",
    "    # Payload to send in the POST request\n",
    "    payload = {\n",
    "        \"celltype\": cell,\n",
    "        \"n_markers\":50,\n",
    "        \"organism\":\"NCBITaxon:9606\",\n",
    "        \"test\":\"ttest\",\n",
    "        \"tissue\":tissue\n",
    "    }\n",
    "\n",
    "    # Send POST request\n",
    "    return requests.post(url, json=payload).json()['marker_genes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_marker(\"UBERON:0001043\", \"cell CL:1000615\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsv2 = main_data_analysisv2(ensembl_df, TARGET_UBERON_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframe_as_markdown(resultsv2[23])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
